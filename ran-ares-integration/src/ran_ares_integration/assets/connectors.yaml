connectors:
  huggingface:
    type: ares.connectors.huggingface.HuggingFaceConnector
    name: huggingface
    model_config:
      pretrained_model_name_or_path: 'Qwen/Qwen2-0.5B-Instruct'
      torch_dtype: 'bfloat16'
    tokenizer_config:
      pretrained_model_name_or_path: 'Qwen/Qwen2-0.5B-Instruct'
      padding_side: 'left'
    generate_kwargs:
      chat_template:
        return_tensors: 'pt'
        thinking: true,
        return_dict: true,
        add_generation_prompt: true,
      generate_params:
        max_new_tokens: 50
    seed: 42
    device: auto
  watsonx_agent:
    type: ares.connectors.watsonx_agent_connector.WatsonxAgentConnector
    name: watsonx_agent
    api_config:
      api_endpoint: https://us-south.ml.cloud.ibm.com/ml/v4/deployments/INSERT_YOUR_DEPLOYMENT_ID/ai_service?version=2021-05-01
      timeout: 200
      header:
        Content-Type: "application/json"
        Authorization: "Bearer $HEADER_TAG"
      request_template:
        messages: "$MESSAGES"
      prepend_message_queue: True
      other:
        iam_url: https://iam.cloud.ibm.com/identity/token
        grant_type: urn:ibm:params:oauth:grant-type:apikey
        token_response_timeout: 400
  watsonx:
    type: ares.connectors.watsonx_connector.WatsonxConnector
    name: watsonx
    model_id: "ibm/granite-3-3-8b-instruct"
    chat: True
    add_assistant: True
    system_prompt: "You are helpful assistant"
    assistant_response: "Sure,"
    model_config:
      min_new_tokens: 0
      max_new_tokens: 1000
      decoding_method: greedy
      repetition_penalty: 1
    generate_kwargs:
      guardrails: true
      guardrails_hap_params:
        input: true
        output: true
        threshold: 0.45
      guardrails_pii_params:
        input: true
        output: true
        mask:
        remove_entity_value: true
    hap_response: I'm sorry, I cannot return harmful content
    pii_response: I'm sorry, I cannot return sensitive content
  watsonx_rest:
    type: ares.connectors.watsonx_rest_connector.WatsonxRESTConnector
    name: watsonx_rest_granite
    api_config:
      api_endpoint: https://INSERT_YOUR_WATSONX_URL/ml/v1/text/chat?version=2024-03-14  # https://cloud.ibm.com/apidocs/watsonx-ai#text-chat
      timeout: 200
      header:
        Content-Type: "application/json"
        Authorization: "Bearer $HEADER_TAG"
        Accept: "application/json"
      request_template:
        model_id: "ibm/granite-3-3-8b-instruct"
        messages: "$MESSAGES"
        parameters:
          max_new_tokens: 100
          time_limit: 1000
      other:
        iam_url: https://iam.cloud.ibm.com/identity/token
        grant_type: urn:ibm:params:oauth:grant-type:apikey
        token_response_timeout: 40
  shieldgemma-2b:
    type: ares.connectors.guardrails.shield_gemma_hf.ShieldGemmaHF
    name: shieldgemma-2b
    model_config:
      pretrained_model_name_or_path: 'google/shieldgemma-2b'
      torch_dtype: 'bfloat16'
    tokenizer_config:
      pretrained_model_name_or_path: 'google/shieldgemma-2b'
      padding_side: 'left'
    generate_kwargs:
      chat_template:
        return_tensors: 'pt'
        return_dict: true,
        add_generation_prompt: true,
      generate_params:
        max_new_tokens: 20
    device: auto
  granite-guardian-3.0:
    type: ares.connectors.guardrails.granite_guardian_hf.GraniteGuardianHF
    name: granite-guardian-3.0-2
    model_config:
      pretrained_model_name_or_path: 'ibm-granite/granite-guardian-3.0-2b'
      torch_dtype: 'bfloat16'
    tokenizer_config:
      pretrained_model_name_or_path: 'ibm-granite/granite-guardian-3.0-2b'
      padding_side: 'left'
    generate_kwargs:
      chat_template:
        return_tensors: 'pt'
        return_dict: true,
        add_generation_prompt: true,
      generate_params:
        max_new_tokens: 20
    device: auto
    input_risk_name: 'harm'
    output_risk_name: 'harm'
  granite-guardian-3.1:
    type: ares.connectors.guardrails.granite_guardian_hf.GraniteGuardianHF
    name: granite-guardian-3.0-2
    model_config:
      pretrained_model_name_or_path: 'ibm-granite/granite-guardian-3.1-2b'
    tokenizer_config:
      pretrained_model_name_or_path: 'ibm-granite/granite-guardian-3.1-2b'
    generate_kwargs:
      generate_params:
        max_new_tokens: 20
    device: auto
    input_risk_name: 'harm'
    output_risk_name: 'harm'
  harmbench-eval-llama:
    type: ares.connectors.huggingface.HuggingFaceConnector
    name: cais/HarmBench-Llama-2-13b-cls
    model_config:
      pretrained_model_name_or_path: 'cais/HarmBench-Llama-2-13b-cls'
      torch_dtype: 'float16'
    tokenizer_config:
      pretrained_model_name_or_path: 'cais/HarmBench-Llama-2-13b-cls'
      truncation_side: 'left'
    generate_kwargs:
      generate_params:
        max_new_tokens: 1
        do_sample: False
    device: "auto"
